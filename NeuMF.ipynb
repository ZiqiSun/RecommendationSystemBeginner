{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuMF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXNa+kfIWmKAWnlqo90xUr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiqiSun/RecommendationSystemBeginner/blob/main/NeuMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pszn2xTS2zP2"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRHsW1eE24yV",
        "outputId": "00f258df-6ef7-4740-a09c-bfa822b98c09"
      },
      "source": [
        "a = torch.rand(20,8)\n",
        "b = torch.rand(20,8)\n",
        "c = torch.cat([a,b],dim=1)\n",
        "c.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx61uUlI3lD9",
        "outputId": "9f103d79-307e-4c65-ce00-8247ce6fec16"
      },
      "source": [
        "linear_layer = torch.nn.Linear(in_features=16, out_features=1)\n",
        "d = linear_layer(c)\n",
        "d.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHVqupiU3-xW",
        "outputId": "fdb72a23-b976-4286-e96f-8b90298a6a56"
      },
      "source": [
        "e = torch.sigmoid(d)\n",
        "e.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWRnFfI4FtN",
        "outputId": "52c58a35-6f37-4758-9de8-80ad27341a9b"
      },
      "source": [
        "print(e.squeeze(1))\n",
        "print(e)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5894, 0.5087, 0.5065, 0.5543, 0.5872, 0.6071, 0.5238, 0.5505, 0.5750,\n",
            "        0.5295, 0.5933, 0.5247, 0.5655, 0.5756, 0.5666, 0.6100, 0.5269, 0.5206,\n",
            "        0.5620, 0.5511], grad_fn=<SqueezeBackward1>)\n",
            "tensor([[0.5894],\n",
            "        [0.5087],\n",
            "        [0.5065],\n",
            "        [0.5543],\n",
            "        [0.5872],\n",
            "        [0.6071],\n",
            "        [0.5238],\n",
            "        [0.5505],\n",
            "        [0.5750],\n",
            "        [0.5295],\n",
            "        [0.5933],\n",
            "        [0.5247],\n",
            "        [0.5655],\n",
            "        [0.5756],\n",
            "        [0.5666],\n",
            "        [0.6100],\n",
            "        [0.5269],\n",
            "        [0.5206],\n",
            "        [0.5620],\n",
            "        [0.5511]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9w2ZgW89drc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import heapq\n",
        "import pdb\n",
        "\n",
        "from time import time\n",
        "from scipy.sparse import load_npz\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from utils import get_train_instances, get_scores\n",
        "from gmf import GMF, train, evaluate, checkpoint\n",
        "from mlp import MLP\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'  # assign GPU\n",
        "\n",
        "def parse_args():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # dirnames\n",
        "    parser.add_argument(\"--datadir\", type=str, default=\".\",\n",
        "        help=\"data directory.\")\n",
        "    parser.add_argument(\"--modeldir\", type=str, default=\"./models\",\n",
        "        help=\"models directory\")\n",
        "    parser.add_argument(\"--dataname\", type=str, default=\"neuralcf_split.npz\",\n",
        "        help=\"npz file with dataset\")\n",
        "    parser.add_argument(\"--train_matrix\", type=str, default=\"neuralcf_train_sparse.npz\",\n",
        "        help=\"train matrix for faster iteration\")\n",
        "\n",
        "    # general parameter\n",
        "    parser.add_argument(\"--epochs\", type=int, default=20,\n",
        "        help=\"number of epochs.\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1024,\n",
        "        help=\"batch size.\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.001,\n",
        "        help=\"learning rate.\")\n",
        "    parser.add_argument(\"--learner\", type=str, default=\"adam\",\n",
        "        help=\"Specify an optimizer: adagrad, adam, rmsprop, sgd\")\n",
        "    parser.add_argument(\"--lr_scheduler\", action=\"store_true\",\n",
        "        help=\"boolean to set the use of CyclicLR during training\")\n",
        "\n",
        "    # GMF set up\n",
        "    parser.add_argument(\"--n_emb\", type=int, default=8,\n",
        "        help=\"embedding size for the GMF part.\")\n",
        "\n",
        "    # MLP set up\n",
        "    parser.add_argument(\"--layers\", type=str, default=\"[64,32,16,8]\",\n",
        "        help=\"layer architecture. The first elements is used for the embedding \\\n",
        "        layers for the MLP part and equals n_emb*2\")\n",
        "    parser.add_argument(\"--dropouts\", type=str, default=\"[0.,0.,0.]\",\n",
        "        help=\"dropout per dense layer. len(dropouts) = len(layers)-1\")\n",
        "\n",
        "    # regularization\n",
        "    parser.add_argument(\"--l2reg\", type=float, default=0.,\n",
        "        help=\"l2 regularization.\")\n",
        "\n",
        "    # Pretrained model names\n",
        "    parser.add_argument(\"--freeze\", type=int, default=0,\n",
        "        help=\"freeze all but the last output layer where \\\n",
        "        weights are combined\")\n",
        "    parser.add_argument(\"--mf_pretrain\", type=str, default=\"GMF_bs_1024_lr_001_n_emb_8_lrnr_adam_lrs_wolrs.pt\",\n",
        "        help=\"Specify the pretrain model filename for GMF part. \\\n",
        "        If empty, no pretrain will be used\")\n",
        "    parser.add_argument(\"--mlp_pretrain\", type=str, default=\"MLP_bs_1024_reg_00_lr_001_n_emb_32_ll_8_dp_wodp_lrnr_adam_lrs_wolrs.pt\",\n",
        "        help=\"Specify the pretrain model filename for MLP part. \\\n",
        "        If empty, no pretrain will be used\")\n",
        "\n",
        "    # Experiment set up\n",
        "    parser.add_argument(\"--validate_every\", type=int, default=1,\n",
        "        help=\"validate every n epochs\")\n",
        "    parser.add_argument(\"--save_model\", type=int, default=1)\n",
        "    parser.add_argument(\"--n_neg\", type=int, default=4,\n",
        "        help=\"number of negative instances to consider per positive instance.\")\n",
        "    parser.add_argument(\"--topk\", type=int, default=10,\n",
        "        help=\"number of items to retrieve for recommendation.\")\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, n_user, n_item, n_emb, layers, dropouts):\n",
        "        super(NeuMF, self).__init__()\n",
        "\n",
        "        self.layers = layers\n",
        "        self.n_layers = len(layers)\n",
        "        self.dropouts = dropouts\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "\n",
        "        self.mf_embeddings_user = nn.Embedding(n_user, n_emb)\n",
        "        self.mf_embeddings_item = nn.Embedding(n_item, n_emb)\n",
        "\n",
        "        self.mlp_embeddings_user = nn.Embedding(n_user, layers[0]//2)\n",
        "        self.mlp_embeddings_item = nn.Embedding(n_item, layers[0]//2)\n",
        "        self.mlp = nn.Sequential()\n",
        "        for i in range(1,self.n_layers):\n",
        "            self.mlp.add_module(\"linear%d\" %i, nn.Linear(layers[i-1],layers[i]))\n",
        "            self.mlp.add_module(\"relu%d\" %i, torch.nn.ReLU())\n",
        "            self.mlp.add_module(\"dropout%d\" %i , torch.nn.Dropout(p=dropouts[i-1]))\n",
        "\n",
        "        self.out = nn.Linear(in_features=n_emb+layers[-1], out_features=1)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Embedding):\n",
        "                nn.init.normal_(m.weight)\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        mf_user_emb = self.mf_embeddings_user(users)\n",
        "        mf_item_emb = self.mf_embeddings_item(items)\n",
        "        mlp_user_emb = self.mlp_embeddings_user(users)\n",
        "        mlp_item_emb = self.mlp_embeddings_item(items)\n",
        "\n",
        "        mf_emb_vector = mf_user_emb * mf_item_emb\n",
        "        mlp_emb_vector = torch.cat([mlp_user_emb, mlp_item_emb], dim=1)\n",
        "        mlp_emb_vector = self.mlp(mlp_emb_vector)\n",
        "\n",
        "        # Task-3: replace 'tensor1' and 'tensor2' with two proper tensors in below code\n",
        "        emb_vector = torch.cat([mf_emb_vector, mlp_emb_vector], dim=1)\n",
        "        preds = torch.sigmoid(self.out(emb_vector))\n",
        "\n",
        "        return preds\n",
        "\n",
        "\n",
        "def load_pretrain_model(model, gmf_model, mlp_model):\n",
        "\n",
        "    # MF embeddings\n",
        "    model.mf_embeddings_item.weight = gmf_model.embeddings_item.weight\n",
        "    model.mf_embeddings_user.weight = gmf_model.embeddings_user.weight\n",
        "\n",
        "    # MLP embeddings\n",
        "    model.mlp_embeddings_item.weight = mlp_model.embeddings_item.weight\n",
        "    model.mlp_embeddings_user.weight = mlp_model.embeddings_user.weight\n",
        "\n",
        "    # MLP layers\n",
        "    model_dict = model.state_dict()\n",
        "    mlp_layers_dict = mlp_model.state_dict()\n",
        "    mlp_layers_dict = {k: v for k, v in mlp_layers_dict.items() if 'linear' in k}\n",
        "    model_dict.update(mlp_layers_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "    # Prediction weights\n",
        "    mf_prediction_weight, mf_prediction_bias = gmf_model.out.weight, gmf_model.out.bias\n",
        "    mlp_prediction_weight, mlp_prediction_bias = mlp_model.out.weight, mlp_model.out.bias\n",
        "\n",
        "    new_weight = torch.cat([mf_prediction_weight, mlp_prediction_weight], dim=1)\n",
        "    new_bias = mf_prediction_bias + mlp_prediction_bias\n",
        "    model.out.weight = torch.nn.Parameter(0.5*new_weight)\n",
        "    model.out.bias = torch.nn.Parameter(0.5*new_bias)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parse_args()\n",
        "\n",
        "    datadir = args.datadir\n",
        "    dataname = args.dataname\n",
        "    train_matrix = args.train_matrix\n",
        "    modeldir = args.modeldir\n",
        "\n",
        "    epochs = args.epochs\n",
        "    batch_size = args.batch_size\n",
        "    lr = args.lr\n",
        "    learner = args.learner\n",
        "    lr_scheduler = args.lr_scheduler\n",
        "    lrs = \"wlrs\" if lr_scheduler else \"wolrs\"\n",
        "\n",
        "    n_emb = args.n_emb\n",
        "\n",
        "    layers = eval(args.layers)\n",
        "    dropouts = eval(args.dropouts)\n",
        "\n",
        "    freeze = bool(args.freeze)\n",
        "    mf_pretrain = os.path.join(modeldir, args.mf_pretrain)\n",
        "    mlp_pretrain = os.path.join(modeldir, args.mlp_pretrain)\n",
        "    with_pretrained = \"wpret\" if os.path.isfile(mf_pretrain) else \"wopret\"\n",
        "    is_frozen = \"frozen\" if freeze else \"trainable\"\n",
        "\n",
        "    l2reg = args.l2reg\n",
        "\n",
        "    validate_every = args.validate_every\n",
        "    save_model = bool(args.save_model)\n",
        "    n_neg = args.n_neg\n",
        "    topk = args.topk\n",
        "\n",
        "    modelfname = \"NeuMF\" + \\\n",
        "        \"_\" + with_pretrained + \\\n",
        "        \"_\" + is_frozen + \\\n",
        "        \"_\" + learner + \\\n",
        "        \"_\".join([\"_lrs\", lrs]) + \\\n",
        "        \".pt\"\n",
        "    modelpath = os.path.join(modeldir, modelfname)\n",
        "    resultsdfpath = os.path.join(modeldir, 'results_df.p')\n",
        "\n",
        "    dataset = np.load(os.path.join(datadir, dataname))\n",
        "    train_ratings = load_npz(os.path.join(datadir, train_matrix)).todok()\n",
        "    test_ratings, negatives = dataset['test_negative'], dataset['negatives']\n",
        "    n_users, n_items = dataset['n_users'].item(), dataset['n_items'].item()\n",
        "\n",
        "    test_loader = DataLoader(dataset=test_ratings,\n",
        "        batch_size=1000,\n",
        "        shuffle=False\n",
        "        )\n",
        "\n",
        "    model = NeuMF(n_users, n_items, n_emb, layers, dropouts)\n",
        "    if os.path.isfile(mf_pretrain) and os.path.isfile(mlp_pretrain):\n",
        "        gmf_model = GMF(n_users, n_items, n_emb)\n",
        "        gmf_model.load_state_dict(torch.load(mf_pretrain))\n",
        "        mlp_model = MLP(n_users, n_items, layers, dropouts)\n",
        "        mlp_model.load_state_dict(torch.load(mlp_pretrain))\n",
        "        model = load_pretrain_model(model, gmf_model, mlp_model)\n",
        "        print(\"Load pretrained GMF {} and MLP {} models done. \".format(mf_pretrain, mlp_pretrain))\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    if freeze:\n",
        "        for name, layer in model.named_parameters():\n",
        "            if not (\"out\" in name):\n",
        "                layer.requires_grad = False\n",
        "\n",
        "    # or this and pass train_parametes to the optimizer\n",
        "    # train_parametes = model.out.parameters() if freeze else model.parameters()\n",
        "\n",
        "    if learner.lower() == \"adagrad\":\n",
        "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=l2reg)\n",
        "    elif learner.lower() == \"rmsprop\":\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=l2reg,\n",
        "            momentum=0.9)\n",
        "    elif learner.lower() == \"adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2reg)\n",
        "    else:\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=l2reg,\n",
        "            momentum=0.9, nesterov=True)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    # trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    # print(trainable_params)\n",
        "\n",
        "    training_steps = ((len(train_ratings)+len(train_ratings)*n_neg)//batch_size)+1\n",
        "    step_size = training_steps*10\n",
        "    cycle_momentum = True\n",
        "    if learner.lower() == \"adagrad\" or learner.lower() == \"adam\":\n",
        "        cycle_momentum=False\n",
        "    if lr_scheduler:\n",
        "        scheduler = CyclicLR(optimizer, step_size_up=step_size, base_lr=lr/10., max_lr=lr,\n",
        "            cycle_momentum=cycle_momentum)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    best_hr, best_ndcgm, best_iter=0,0,0\n",
        "    for epoch in range(1,epochs+1):\n",
        "        t1 = time()\n",
        "        loss = train(model, criterion, optimizer, scheduler, epoch, batch_size,\n",
        "            use_cuda, train_ratings, negatives, n_items, n_neg)\n",
        "        t2 = time()\n",
        "        if epoch % validate_every == 0:\n",
        "            (hr, ndcg) = evaluate(model, test_loader, use_cuda, topk)\n",
        "            print(\"Epoch: {} {:.2f}s, LOSS = {:.4f}, HR = {:.4f}, NDCG = {:.4f}, validated in {:.2f}s\".\n",
        "                format(epoch, t2-t1, loss, hr, ndcg, time()-t2))\n",
        "            if hr > best_hr:\n",
        "                iter_loss, best_hr, best_ndcg, best_iter, train_time = \\\n",
        "                    loss, hr, ndcg, epoch, t2-t1\n",
        "                if save_model:\n",
        "                    checkpoint(model, modelpath)\n",
        "\n",
        "    print(\"End. Best Iteration {}: HR = {:.4f}, NDCG = {:.4f}. \".format(best_iter, best_hr, best_ndcg))\n",
        "    if save_model:\n",
        "        print(\"The best NeuMF model is saved to {}\".format(modelpath))\n",
        "\n",
        "    if save_model:\n",
        "        cols = [\"modelname\", \"iter_loss\",\"best_hr\", \"best_ndcg\", \"best_iter\",\"train_time\"]\n",
        "        vals = [modelfname, iter_loss, best_hr, best_ndcg, best_iter, train_time]\n",
        "        if not os.path.isfile(resultsdfpath):\n",
        "            results_df = pd.DataFrame(columns=cols)\n",
        "            experiment_df = pd.DataFrame(data=[vals], columns=cols)\n",
        "            results_df = results_df.append(experiment_df, ignore_index=True)\n",
        "            results_df.to_pickle(resultsdfpath)\n",
        "        else:\n",
        "            results_df = pd.read_pickle(resultsdfpath)\n",
        "            experiment_df = pd.DataFrame(data=[vals], columns=cols)\n",
        "            results_df = results_df.append(experiment_df, ignore_index=True)\n",
        "            results_df.to_pickle(resultsdfpath)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}